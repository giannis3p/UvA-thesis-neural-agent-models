{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.constraints import MinMaxNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/conc_txt_test\"\n",
    "output_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data\"\n",
    "\n",
    "# create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# iterate through files in input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        try:\n",
    "            # construct input and output file paths\n",
    "            input_filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "\n",
    "            # read txt file and remove leading and trailing quotation marks from each line\n",
    "            with open(input_filepath, 'r') as file:\n",
    "                lines = [line.strip().strip('\"') for line in file.readlines()]\n",
    "\n",
    "            # remove every other line (gap lines)\n",
    "            lines = [line for index, line in enumerate(lines) if index % 2 == 0]\n",
    "\n",
    "            # check if all lines have the same number of elements\n",
    "            num_elements = len(lines[0].split(','))\n",
    "            if all(len(line.split(',')) == num_elements for line in lines):\n",
    "                # convert to df and save as csv\n",
    "                df = pd.DataFrame([line.split(',') for line in lines])\n",
    "                df.to_csv(output_filepath, index=False, header=False, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "                print(f\"Converted {input_filepath} to {output_filepath}\")\n",
    "            else:\n",
    "                print(f\"Skipping {input_filepath}: Inconsistent number of elements in lines\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {input_filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat the cytokines data to create the 'test_data_concat' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cytokine_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data\"\n",
    "output_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data_concat\"\n",
    "\n",
    "def concat_files_in_folder(folder_path):\n",
    "    test_data_concat = pd.DataFrame()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_data_concat = pd.concat([test_data_concat, df])\n",
    "    return test_data_concat\n",
    "\n",
    "def sort_by_mcsteps(data):\n",
    "    return data.sort_values(by='mcsteps')\n",
    "\n",
    "concatenated_data = concat_files_in_folder(base_cytokine_folder)\n",
    "\n",
    "sorted_data = sort_by_mcsteps(concatenated_data)\n",
    "\n",
    "output_filepath = os.path.join(output_folder, \"sorted_concatenated_data.csv\")\n",
    "sorted_data.to_csv(output_filepath, index=False)\n",
    "print(f\"Sorted and concatenated data saved to: {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data for test_data_concat and drop zCOM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mcsteps  xCOM  yCOM           il8  il1  il6  il10  tnf  tgf\n",
      "0        0    33    22  3.750408e-07  0.0  0.0   0.0  0.0  0.0\n",
      "1        0    11    32  4.793328e-09  0.0  0.0   0.0  0.0  0.0\n",
      "2        0    30    35  8.997935e-09  0.0  0.0   0.0  0.0  0.0\n",
      "3        0    17    40  1.781103e-08  0.0  0.0   0.0  0.0  0.0\n",
      "4        0    21    23  4.789621e-09  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "sorted_concatenated_csv = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data_concat/sorted_concatenated_data.csv\"\n",
    "data = pd.read_csv(sorted_concatenated_csv)\n",
    "data.drop(columns=['zCOM'], inplace=True)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time  xCOM  yCOM           il8           il1           il6  \\\n",
      "0         0    33    22  3.750408e-07  0.000000e+00  0.000000e+00   \n",
      "1         0    11    32  4.793328e-09  0.000000e+00  0.000000e+00   \n",
      "2         0    30    35  8.997935e-09  0.000000e+00  0.000000e+00   \n",
      "3         0    17    40  1.781103e-08  0.000000e+00  0.000000e+00   \n",
      "4         0    21    23  4.789621e-09  0.000000e+00  0.000000e+00   \n",
      "...     ...   ...   ...           ...           ...           ...   \n",
      "86155   100    49    35 -8.886183e-11  6.343394e-10  1.206925e-08   \n",
      "86156   100    36     4  1.334245e-07  1.665160e-07  1.305691e-08   \n",
      "86157   100    49    44 -1.233990e-10  1.178848e-09  1.615457e-07   \n",
      "86158   100    45    10  3.257988e-07  4.403049e-08  1.749928e-07   \n",
      "86159   100    35    38  2.107191e-05  9.170692e-08  5.693712e-19   \n",
      "\n",
      "               il10           tnf           tgf  \n",
      "0      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "1      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "2      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "3      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "4      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "...             ...           ...           ...  \n",
      "86155  3.819835e-10  1.979543e-10  4.400244e-06  \n",
      "86156  4.469681e-10  3.720676e-07  7.833499e-06  \n",
      "86157  3.270504e-08  9.659641e-08  6.022260e-06  \n",
      "86158  3.550616e-08  1.001522e-07  6.226569e-06  \n",
      "86159  5.103635e-25  4.620498e-09  2.838544e-12  \n",
      "\n",
      "[86160 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data['time'] = (data['mcsteps'] / 10000).astype(int)\n",
    "data = data[['time'] + [col for col in data.columns if col != 'time']]\n",
    "data.drop(columns=['mcsteps'], inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define cytokines\n",
    "cytokines = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "# get unique time values\n",
    "unique_time = data['time'].unique()\n",
    "\n",
    "arrays = {}\n",
    "\n",
    "# iterate over unique time values\n",
    "for time in unique_time:\n",
    "    # filter data for current value of time\n",
    "    data_time = data[data['time'] == time]\n",
    "    \n",
    "    # initialize 50x50x6 array for current value of time\n",
    "    array = np.zeros((50, 50, len(cytokines)))\n",
    "    \n",
    "    # get X and Y coordinates\n",
    "    x = data_time['xCOM'].astype(int)\n",
    "    y = data_time['yCOM'].astype(int)\n",
    "    \n",
    "    # get cytokine concentrations\n",
    "    concentrations = data_time[['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']].values\n",
    "    \n",
    "    # assign cytokine concentrations to corresponding position in array\n",
    "    array[x, y, :] = concentrations\n",
    "    \n",
    "    # store array for current value of time\n",
    "    arrays[time] = array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of arrays: 101\n",
      "Shape of the array: (50, 50, 6)\n",
      "Value at position (35,20): [1.7285698e-05 7.6371320e-11 2.9109778e-14 5.1850766e-18 9.9240220e-17\n",
      " 1.7688583e-11]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of arrays:\", len(arrays))\n",
    "array = arrays[91]\n",
    "print(\"Shape of the array:\", array.shape)\n",
    "print(\"Value at position (39,25):\", array[39,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "input_sequences = []\n",
    "output_values = []\n",
    "\n",
    "# convert dictionary values to a list of arrays\n",
    "arrays_list = [arrays[key] for key in sorted(arrays.keys())]\n",
    "\n",
    "# convert 'arrays' list to numpy array\n",
    "arrays_np = np.array(arrays_list)\n",
    "\n",
    "for i in range(len(arrays_np) - sequence_length):\n",
    "    input_seq = arrays_np[i:i+sequence_length]  # input sequence of arrays\n",
    "    output_val = arrays_np[i+sequence_length]   # array at next time step\n",
    "    \n",
    "    input_sequences.append(input_seq)\n",
    "    output_values.append(output_val)\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "output_values = np.array(output_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 10, 50, 50, 6)\n",
      "(91, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences.shape)\n",
    "print(output_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 64)                3856640   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 50)                3250      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 15000)             765000    \n",
      "                                                                 \n",
      " reshape_12 (Reshape)        (None, 50, 50, 6)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,627,440\n",
      "Trainable params: 4,627,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "2/2 [==============================] - 2s 412ms/step - loss: 4.9562e-12 - val_loss: 1.1523e-11 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.8646e-12 - val_loss: 1.1311e-11 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.7287e-12 - val_loss: 1.1049e-11 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 418ms/step - loss: 4.5634e-12 - val_loss: 1.0751e-11 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.3757e-12 - val_loss: 1.0423e-11 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.1728e-12 - val_loss: 1.0071e-11 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.9622e-12 - val_loss: 9.7064e-12 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7421e-12 - val_loss: 9.3382e-12 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 3.5221e-12 - val_loss: 8.9659e-12 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.3030e-12 - val_loss: 8.5884e-12 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.0892e-12 - val_loss: 8.2119e-12 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2.8761e-12 - val_loss: 7.8428e-12 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.6746e-12 - val_loss: 7.4842e-12 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.4794e-12 - val_loss: 7.1389e-12 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 2.2966e-12 - val_loss: 6.8048e-12 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.1250e-12 - val_loss: 6.4829e-12 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.9650e-12 - val_loss: 6.1762e-12 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.8124e-12 - val_loss: 5.8822e-12 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.6762e-12 - val_loss: 5.5997e-12 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.5495e-12 - val_loss: 5.3353e-12 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.4313e-12 - val_loss: 5.0869e-12 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.3281e-12 - val_loss: 4.8518e-12 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.2364e-12 - val_loss: 4.6356e-12 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.1501e-12 - val_loss: 4.4366e-12 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0768e-12 - val_loss: 4.2475e-12 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.0124e-12 - val_loss: 4.0696e-12 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.5607e-13 - val_loss: 3.9078e-12 - lr: 1.0000e-04\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.0282e-13 - val_loss: 3.7578e-12 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.6164e-13 - val_loss: 3.6157e-12 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.2347e-13 - val_loss: 3.4853e-12 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 7.9234e-13 - val_loss: 3.3669e-12 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 7.6723e-13 - val_loss: 3.2649e-12 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 7.4450e-13 - val_loss: 3.1776e-12 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 342ms/step - loss: 7.2782e-13 - val_loss: 3.0998e-12 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.1428e-13 - val_loss: 3.0310e-12 - lr: 1.0000e-04\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 7.0339e-13 - val_loss: 2.9712e-12 - lr: 1.0000e-04\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.9334e-13 - val_loss: 2.9154e-12 - lr: 1.0000e-04\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.8656e-13 - val_loss: 2.8606e-12 - lr: 1.0000e-04\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 6.7984e-13 - val_loss: 2.8094e-12 - lr: 1.0000e-04\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 6.7515e-13 - val_loss: 2.7625e-12 - lr: 1.0000e-04\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.7085e-13 - val_loss: 2.7216e-12 - lr: 1.0000e-04\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.6730e-13 - val_loss: 2.6837e-12 - lr: 1.0000e-04\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 6.6530e-13 - val_loss: 2.6487e-12 - lr: 1.0000e-04\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.6354e-13 - val_loss: 2.6190e-12 - lr: 1.0000e-04\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.6199e-13 - val_loss: 2.5925e-12 - lr: 1.0000e-04\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.6090e-13 - val_loss: 2.5655e-12 - lr: 1.0000e-04\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 6.6015e-13 - val_loss: 2.5363e-12 - lr: 1.0000e-04\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.6054e-13 - val_loss: 2.5106e-12 - lr: 1.0000e-04\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.6002e-13 - val_loss: 2.4919e-12 - lr: 1.0000e-04\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.6009e-13 - val_loss: 2.4772e-12 - lr: 1.0000e-04\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.6020e-13 - val_loss: 2.4666e-12 - lr: 1.0000e-04\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.6034e-13 - val_loss: 2.4607e-12 - lr: 1.0000e-04\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.6034e-13 - val_loss: 2.4553e-12 - lr: 1.0000e-04\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.6043e-13 - val_loss: 2.4473e-12 - lr: 1.0000e-04\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.6052e-13 - val_loss: 2.4385e-12 - lr: 1.0000e-04\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 6.6070e-13 - val_loss: 2.4280e-12 - lr: 1.0000e-04\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 6.6096e-13 - val_loss: 2.4180e-12 - lr: 1.0000e-04\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.6135e-13 - val_loss: 2.4113e-12 - lr: 1.0000e-04\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.6146e-13 - val_loss: 2.4077e-12 - lr: 1.0000e-04\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.6174e-13 - val_loss: 2.4080e-12 - lr: 1.0000e-04\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6179e-13 - val_loss: 2.4103e-12 - lr: 1.0000e-04\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6169e-13 - val_loss: 2.4109e-12 - lr: 1.0000e-04\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6172e-13 - val_loss: 2.4121e-12 - lr: 1.0000e-04\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6172e-13 - val_loss: 2.4104e-12 - lr: 1.0000e-04\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 6.6185e-13 - val_loss: 2.4099e-12 - lr: 1.0000e-04\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.6185e-13 - val_loss: 2.4124e-12 - lr: 1.0000e-04\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6177e-13 - val_loss: 2.4129e-12 - lr: 1.0000e-04\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6173e-13 - val_loss: 2.4111e-12 - lr: 1.0000e-04\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 5s 56ms/step - loss: 6.6187e-13 - val_loss: 2.4110e-12 - lr: 1.0000e-04\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6191e-13 - val_loss: 2.4129e-12 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.6189e-13 - val_loss: 2.4127e-12 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 6.6193e-13 - val_loss: 2.4152e-12 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6188e-13 - val_loss: 2.4200e-12 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6155e-13 - val_loss: 2.4245e-12 - lr: 1.0000e-04\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6135e-13 - val_loss: 2.4333e-12 - lr: 1.0000e-04\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6103e-13 - val_loss: 2.4451e-12 - lr: 1.0000e-04\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 6.6074e-13 - val_loss: 2.4589e-12 - lr: 1.0000e-04\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6077e-13 - val_loss: 2.4688e-12 - lr: 1.0000e-04\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6033e-13 - val_loss: 2.4737e-12 - lr: 1.0000e-04\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6020e-13 - val_loss: 2.4802e-12 - lr: 1.0000e-04\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.6034e-13 - val_loss: 2.4850e-12 - lr: 1.0000e-04\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6010e-13 - val_loss: 2.4857e-12 - lr: 1.0000e-04\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6019e-13 - val_loss: 2.4801e-12 - lr: 1.0000e-04\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.6031e-13 - val_loss: 2.4715e-12 - lr: 1.0000e-04\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.6017e-13 - val_loss: 2.4714e-12 - lr: 1.0000e-04\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6010e-13 - val_loss: 2.4761e-12 - lr: 1.0000e-04\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 6.6000e-13 - val_loss: 2.4843e-12 - lr: 1.0000e-04\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.5999e-13 - val_loss: 2.4941e-12 - lr: 1.0000e-04\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6015e-13 - val_loss: 2.4974e-12 - lr: 1.0000e-04\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.5997e-13 - val_loss: 2.4968e-12 - lr: 1.0000e-04\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.5997e-13 - val_loss: 2.4966e-12 - lr: 1.0000e-04\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.5995e-13 - val_loss: 2.4944e-12 - lr: 1.0000e-04\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 6.5994e-13 - val_loss: 2.4914e-12 - lr: 1.0000e-04\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6003e-13 - val_loss: 2.4900e-12 - lr: 1.0000e-04\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6000e-13 - val_loss: 2.4895e-12 - lr: 1.0000e-04\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.5999e-13 - val_loss: 2.4878e-12 - lr: 1.0000e-04\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.5997e-13 - val_loss: 2.4888e-12 - lr: 1.0000e-04\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.5999e-13 - val_loss: 2.4889e-12 - lr: 1.0000e-04\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.5998e-13 - val_loss: 2.4871e-12 - lr: 1.0000e-04\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.5998e-13 - val_loss: 2.4871e-12 - lr: 1.0000e-04\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6066e-13 - val_loss: 2.4624e-12 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.6079e-13 - val_loss: 2.3984e-12 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.6249e-13 - val_loss: 2.3317e-12 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.6575e-13 - val_loss: 2.2470e-12 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 6.7319e-13 - val_loss: 2.1740e-12 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.8187e-13 - val_loss: 2.1731e-12 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.8011e-13 - val_loss: 2.2605e-12 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.7029e-13 - val_loss: 2.3890e-12 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6446e-13 - val_loss: 2.4979e-12 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.6052e-13 - val_loss: 2.5794e-12 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 6.6192e-13 - val_loss: 2.6540e-12 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6351e-13 - val_loss: 2.7204e-12 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6888e-13 - val_loss: 2.7493e-12 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.7100e-13 - val_loss: 2.7315e-12 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6986e-13 - val_loss: 2.6578e-12 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6266e-13 - val_loss: 2.4606e-12 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6256e-13 - val_loss: 2.2817e-12 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.7210e-13 - val_loss: 2.2082e-12 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.7884e-13 - val_loss: 2.2414e-12 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.7716e-13 - val_loss: 2.2953e-12 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6993e-13 - val_loss: 2.3426e-12 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6679e-13 - val_loss: 2.4069e-12 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.6277e-13 - val_loss: 2.4326e-12 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.6186e-13 - val_loss: 2.4024e-12 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6298e-13 - val_loss: 2.3632e-12 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6508e-13 - val_loss: 2.3639e-12 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6570e-13 - val_loss: 2.3357e-12 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6613e-13 - val_loss: 2.2841e-12 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6952e-13 - val_loss: 2.2880e-12 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 6.6898e-13 - val_loss: 2.3542e-12 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.6456e-13 - val_loss: 2.5045e-12 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.6221e-13 - val_loss: 2.7205e-12 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6735e-13 - val_loss: 2.9496e-12 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.9122e-13 - val_loss: 3.1402e-12 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 7.1759e-13 - val_loss: 3.1465e-12 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.1582e-13 - val_loss: 2.9688e-12 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.9078e-13 - val_loss: 2.7080e-12 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.6853e-13 - val_loss: 2.4863e-12 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6260e-13 - val_loss: 2.3657e-12 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 6.6382e-13 - val_loss: 2.3202e-12 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6634e-13 - val_loss: 2.3100e-12 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6713e-13 - val_loss: 2.3838e-12 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6323e-13 - val_loss: 2.5287e-12 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.5950e-13 - val_loss: 2.6938e-12 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6532e-13 - val_loss: 2.8742e-12 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.8415e-13 - val_loss: 2.8944e-12 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.8072e-13 - val_loss: 2.7058e-12 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6501e-13 - val_loss: 2.4547e-12 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6420e-13 - val_loss: 2.2619e-12 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.7223e-13 - val_loss: 2.2011e-12 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.7658e-13 - val_loss: 2.2427e-12 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6.7088e-13 - val_loss: 2.3758e-12 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6419e-13 - val_loss: 2.5413e-12 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6104e-13 - val_loss: 2.6635e-12 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.6585e-13 - val_loss: 2.7059e-12 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6641e-13 - val_loss: 2.6196e-12 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.6155e-13 - val_loss: 2.4563e-12 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6369e-13 - val_loss: 2.3440e-12 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6560e-13 - val_loss: 2.3023e-12 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6811e-13 - val_loss: 2.2768e-12 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6975e-13 - val_loss: 2.3162e-12 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.6777e-13 - val_loss: 2.3993e-12 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6436e-13 - val_loss: 2.4878e-12 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6346e-13 - val_loss: 2.5957e-12 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 6.6538e-13 - val_loss: 2.6893e-12 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.6715e-13 - val_loss: 2.7999e-12 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.7481e-13 - val_loss: 2.9177e-12 - lr: 0.0010\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6.8644e-13 - val_loss: 2.9208e-12 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.8666e-13 - val_loss: 2.8010e-12 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.7497e-13 - val_loss: 2.6091e-12 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6273e-13 - val_loss: 2.4224e-12 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 3s 54ms/step - loss: 6.6408e-13 - val_loss: 2.3037e-12 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6851e-13 - val_loss: 2.3146e-12 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6725e-13 - val_loss: 2.4054e-12 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.6412e-13 - val_loss: 2.4782e-12 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6170e-13 - val_loss: 2.5836e-12 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6308e-13 - val_loss: 2.7305e-12 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.6959e-13 - val_loss: 2.7785e-12 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.7244e-13 - val_loss: 2.7268e-12 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.7155e-13 - val_loss: 2.7028e-12 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6837e-13 - val_loss: 2.7020e-12 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6811e-13 - val_loss: 2.6395e-12 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6374e-13 - val_loss: 2.5548e-12 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.5974e-13 - val_loss: 2.3998e-12 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6396e-13 - val_loss: 2.2463e-12 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.7409e-13 - val_loss: 2.1462e-12 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 6.8832e-13 - val_loss: 2.1026e-12 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.9431e-13 - val_loss: 2.1753e-12 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.8272e-13 - val_loss: 2.3148e-12 - lr: 0.0010\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6723e-13 - val_loss: 2.4326e-12 - lr: 0.0010\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.6023e-13 - val_loss: 2.5677e-12 - lr: 0.0010\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6667e-13 - val_loss: 2.6385e-12 - lr: 0.0010\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.6530e-13 - val_loss: 2.5486e-12 - lr: 0.0010\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6527e-13 - val_loss: 2.4807e-12 - lr: 0.0010\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6360e-13 - val_loss: 2.5291e-12 - lr: 0.0010\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6296e-13 - val_loss: 2.6395e-12 - lr: 0.0010\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6610e-13 - val_loss: 2.7012e-12 - lr: 0.0010\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6788e-13 - val_loss: 2.7373e-12 - lr: 0.0010\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6901e-13 - val_loss: 2.7921e-12 - lr: 0.0010\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.7276e-13 - val_loss: 2.7621e-12 - lr: 0.0010\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.6998e-13 - val_loss: 2.6434e-12 - lr: 0.0010\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.6383e-13 - val_loss: 2.4565e-12 - lr: 0.0010\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6976e-13 - val_loss: 2.3249e-12 - lr: 0.0010\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.6961e-13 - val_loss: 2.3512e-12 - lr: 0.0010\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6649e-13 - val_loss: 2.4221e-12 - lr: 0.0010\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6322e-13 - val_loss: 2.4266e-12 - lr: 0.0010\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6243e-13 - val_loss: 2.3805e-12 - lr: 0.0010\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6470e-13 - val_loss: 2.3492e-12 - lr: 0.0010\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6643e-13 - val_loss: 2.3734e-12 - lr: 0.0010\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.6583e-13 - val_loss: 2.4089e-12 - lr: 0.0010\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6257e-13 - val_loss: 2.3695e-12 - lr: 0.0010\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 6.6394e-13 - val_loss: 2.2957e-12 - lr: 0.0010\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6892e-13 - val_loss: 2.2431e-12 - lr: 0.0010\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.7287e-13 - val_loss: 2.2502e-12 - lr: 0.0010\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.7208e-13 - val_loss: 2.3245e-12 - lr: 0.0010\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.6716e-13 - val_loss: 2.4401e-12 - lr: 0.0010\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6169e-13 - val_loss: 2.5268e-12 - lr: 0.0010\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.6048e-13 - val_loss: 2.6836e-12 - lr: 0.0010\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.6601e-13 - val_loss: 2.9245e-12 - lr: 0.0010\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.8707e-13 - val_loss: 3.1003e-12 - lr: 0.0010\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 7.0906e-13 - val_loss: 3.1225e-12 - lr: 0.0010\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 7.1009e-13 - val_loss: 2.9676e-12 - lr: 0.0010\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.9045e-13 - val_loss: 2.7414e-12 - lr: 0.0010\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.7029e-13 - val_loss: 2.5402e-12 - lr: 0.0010\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.6466e-13 - val_loss: 2.4229e-12 - lr: 0.0010\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 6.6325e-13 - val_loss: 2.3965e-12 - lr: 0.0010\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6318e-13 - val_loss: 2.3888e-12 - lr: 0.0010\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6326e-13 - val_loss: 2.4368e-12 - lr: 0.0010\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 270ms/step - loss: 6.6085e-13 - val_loss: 2.5821e-12 - lr: 0.0010\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.6479e-13 - val_loss: 2.6620e-12 - lr: 0.0010\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6599e-13 - val_loss: 2.6785e-12 - lr: 0.0010\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 6.6652e-13 - val_loss: 2.6532e-12 - lr: 0.0010\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6379e-13 - val_loss: 2.5283e-12 - lr: 0.0010\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.6216e-13 - val_loss: 2.4619e-12 - lr: 0.0010\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6159e-13 - val_loss: 2.4850e-12 - lr: 0.0010\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.6062e-13 - val_loss: 2.5801e-12 - lr: 0.0010\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.6260e-13 - val_loss: 2.6953e-12 - lr: 0.0010\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6793e-13 - val_loss: 2.7668e-12 - lr: 0.0010\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.7194e-13 - val_loss: 2.7801e-12 - lr: 0.0010\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.7167e-13 - val_loss: 2.7159e-12 - lr: 0.0010\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6819e-13 - val_loss: 2.6181e-12 - lr: 0.0010\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 420ms/step - loss: 6.6413e-13 - val_loss: 2.5502e-12 - lr: 0.0010\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.6459e-13 - val_loss: 2.5701e-12 - lr: 0.0010\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6122e-13 - val_loss: 2.6926e-12 - lr: 0.0010\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6627e-13 - val_loss: 2.7559e-12 - lr: 0.0010\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.7149e-13 - val_loss: 2.6717e-12 - lr: 0.0010\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.7043e-13 - val_loss: 2.5558e-12 - lr: 0.0010\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6511e-13 - val_loss: 2.4538e-12 - lr: 0.0010\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6176e-13 - val_loss: 2.2873e-12 - lr: 0.0010\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.6833e-13 - val_loss: 2.1599e-12 - lr: 0.0010\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.8317e-13 - val_loss: 2.2131e-12 - lr: 0.0010\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.8113e-13 - val_loss: 2.3603e-12 - lr: 0.0010\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6786e-13 - val_loss: 2.4770e-12 - lr: 0.0010\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.6314e-13 - val_loss: 2.6057e-12 - lr: 0.0010\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6638e-13 - val_loss: 2.6341e-12 - lr: 0.0010\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 6.6425e-13 - val_loss: 2.5749e-12 - lr: 0.0010\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.6170e-13 - val_loss: 2.5455e-12 - lr: 0.0010\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6163e-13 - val_loss: 2.4818e-12 - lr: 0.0010\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 6.6669e-13 - val_loss: 2.4972e-12 - lr: 0.0010\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.6141e-13 - val_loss: 2.6892e-12 - lr: 0.0010\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6935e-13 - val_loss: 2.8447e-12 - lr: 0.0010\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.7888e-13 - val_loss: 2.8131e-12 - lr: 0.0010\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.7800e-13 - val_loss: 2.7007e-12 - lr: 0.0010\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6857e-13 - val_loss: 2.5568e-12 - lr: 0.0010\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.6209e-13 - val_loss: 2.3811e-12 - lr: 0.0010\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.6326e-13 - val_loss: 2.2785e-12 - lr: 0.0010\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.7063e-13 - val_loss: 2.2642e-12 - lr: 0.0010\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.7308e-13 - val_loss: 2.3637e-12 - lr: 0.0010\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6489e-13 - val_loss: 2.5608e-12 - lr: 0.0010\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6257e-13 - val_loss: 2.7217e-12 - lr: 0.0010\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6844e-13 - val_loss: 2.7729e-12 - lr: 0.0010\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.7261e-13 - val_loss: 2.6766e-12 - lr: 0.0010\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.6530e-13 - val_loss: 2.4695e-12 - lr: 0.0010\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6136e-13 - val_loss: 2.2821e-12 - lr: 0.0010\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 6.7023e-13 - val_loss: 2.1562e-12 - lr: 0.0010\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.8496e-13 - val_loss: 2.1524e-12 - lr: 0.0010\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6.8326e-13 - val_loss: 2.3065e-12 - lr: 0.0010\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6747e-13 - val_loss: 2.5516e-12 - lr: 0.0010\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.6169e-13 - val_loss: 2.7875e-12 - lr: 0.0010\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.7553e-13 - val_loss: 2.9318e-12 - lr: 0.0010\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.8924e-13 - val_loss: 2.9269e-12 - lr: 0.0010\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.8883e-13 - val_loss: 2.8539e-12 - lr: 0.0010\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.7968e-13 - val_loss: 2.7779e-12 - lr: 0.0010\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.7307e-13 - val_loss: 2.7375e-12 - lr: 0.0010\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.6947e-13 - val_loss: 2.8097e-12 - lr: 0.0010\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.7350e-13 - val_loss: 2.9563e-12 - lr: 0.0010\n",
      "Epoch 287/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.6985e-13Restoring model weights from the end of the best epoch: 187.\n",
      "2/2 [==============================] - 1s 661ms/step - loss: 6.8960e-13 - val_loss: 3.0537e-12 - lr: 0.0010\n",
      "Epoch 287: early stopping\n",
      "Training Loss: [4.956155277846541e-12, 4.864622159955756e-12, 4.728743438486838e-12, 4.563420821779296e-12, 4.375734150019461e-12, 4.172789284245804e-12, 3.962222477199573e-12, 3.742077828161605e-12, 3.5220984115347242e-12, 3.3030076070084124e-12, 3.089229176286845e-12, 2.8760817512296644e-12, 2.6746486969653205e-12, 2.4793949445628405e-12, 2.2966463800178083e-12, 2.124967519653853e-12, 1.96497917763494e-12, 1.8123865038952025e-12, 1.6762299014094761e-12, 1.5494957747441696e-12, 1.4312923676124134e-12, 1.3280561546313852e-12, 1.2363519496377817e-12, 1.1500824164539791e-12, 1.0768080220893705e-12, 1.0123806090320264e-12, 9.560689913368225e-13, 9.028152574488968e-13, 8.616405115444148e-13, 8.234716077429316e-13, 7.923415070755502e-13, 7.672252590185114e-13, 7.445019535763653e-13, 7.278234005064776e-13, 7.142826369439803e-13, 7.033862966902837e-13, 6.933363930726466e-13, 6.865608342260243e-13, 6.798366123522692e-13, 6.751515579245249e-13, 6.708529131510543e-13, 6.672982479083434e-13, 6.653025027593407e-13, 6.635382889842723e-13, 6.61986578835011e-13, 6.609029729737204e-13, 6.601492356234084e-13, 6.605430720625638e-13, 6.600160413865186e-13, 6.60087544519794e-13, 6.601955852662822e-13, 6.603405973068521e-13, 6.603365315487053e-13, 6.604311823983633e-13, 6.605239358942194e-13, 6.607048892368073e-13, 6.60961032000057e-13, 6.613462490319411e-13, 6.614636139171126e-13, 6.617430128169621e-13, 6.617897419305963e-13, 6.616898327004017e-13, 6.617212745634038e-13, 6.617173172254742e-13, 6.618526256566004e-13, 6.618452530818275e-13, 6.617690336691018e-13, 6.617278339865473e-13, 6.618686176386446e-13, 6.619130157176079e-13, 6.618931206077427e-13, 6.619255382527001e-13, 6.618830917376473e-13, 6.615536026974289e-13, 6.613520495135639e-13, 6.610319388221375e-13, 6.607419147409976e-13, 6.607711339895461e-13, 6.603346341949035e-13, 6.601969405189978e-13, 6.603368568093571e-13, 6.600950797248928e-13, 6.601881584814007e-13, 6.603122996301503e-13, 6.601718412387048e-13, 6.601040243928158e-13, 6.599951162845896e-13, 6.599874726592736e-13, 6.601500487750378e-13, 6.599730527703795e-13, 6.599708843660346e-13, 6.599497424236711e-13, 6.599361356864064e-13, 6.600281844508504e-13, 6.599992362528451e-13, 6.59993327351005e-13, 6.599748959140728e-13, 6.599935441914395e-13, 6.599773353689609e-13, 6.599833526910182e-13, 6.606568590805662e-13, 6.607864212401782e-13, 6.624876428690252e-13, 6.657493566847306e-13, 6.731925672291694e-13, 6.818699251065485e-13, 6.801054944910456e-13, 6.702916216863586e-13, 6.644643602699007e-13, 6.605175933115104e-13, 6.619221230158567e-13, 6.635089613155065e-13, 6.688766294310478e-13, 6.709981962421674e-13, 6.698613560542077e-13, 6.626586757617348e-13, 6.625618565077318e-13, 6.721045161389716e-13, 6.788358395369565e-13, 6.771631324252458e-13, 6.699265708148827e-13, 6.667936602172686e-13, 6.627689933327852e-13, 6.618572335158335e-13, 6.629842074640235e-13, 6.650806749948501e-13, 6.657041454541379e-13, 6.661308332191196e-13, 6.695165255532487e-13, 6.689843449168842e-13, 6.645563548242361e-13, 6.622116049959104e-13, 6.673549516819643e-13, 6.91215259942396e-13, 7.175898330408215e-13, 7.158172709090249e-13, 6.90776645953517e-13, 6.68532774712044e-13, 6.626011046263758e-13, 6.638168747324924e-13, 6.663367232116746e-13, 6.671307386726943e-13, 6.632322187109796e-13, 6.594979553783964e-13, 6.653212594569247e-13, 6.841494059640907e-13, 6.80715032952417e-13, 6.650146470825458e-13, 6.641960744423192e-13, 6.722267599339193e-13, 6.765846563561162e-13, 6.708818613490597e-13, 6.641921171043896e-13, 6.610422929528847e-13, 6.658465011993853e-13, 6.664095815976656e-13, 6.615512174526494e-13, 6.636894267671167e-13, 6.655995741546017e-13, 6.681127005803145e-13, 6.697549958210869e-13, 6.677690627017452e-13, 6.643591926591697e-13, 6.634630453535018e-13, 6.65381812148258e-13, 6.671507422027767e-13, 6.748061853224796e-13, 6.864422225083544e-13, 6.866615566078482e-13, 6.749707672122629e-13, 6.627325641397896e-13, 6.64083859517467e-13, 6.685069707003388e-13, 6.672495672307988e-13, 6.641182829364434e-13, 6.616951995011555e-13, 6.630763104385762e-13, 6.695856976518533e-13, 6.724402935517904e-13, 6.71547236222314e-13, 6.683653196865036e-13, 6.681112369073816e-13, 6.637403842692235e-13, 6.597374556382984e-13, 6.639627541348003e-13, 6.740906118886392e-13, 6.883177838465371e-13, 6.943093018921265e-13, 6.827223790646653e-13, 6.672282084480008e-13, 6.602287618527602e-13, 6.666702780100398e-13, 6.653048337940115e-13, 6.652707356356868e-13, 6.636001427182125e-13, 6.62959758705034e-13, 6.660979818932933e-13, 6.67876290296604e-13, 6.690115583914136e-13, 6.727586695197407e-13, 6.699776367372068e-13, 6.638336256560573e-13, 6.697597121005372e-13, 6.696083032671496e-13, 6.66489162037126e-13, 6.632229487824048e-13, 6.624271985979091e-13, 6.646998489817646e-13, 6.664296393378566e-13, 6.658281781826703e-13, 6.625718311677187e-13, 6.639374922241814e-13, 6.689242259064199e-13, 6.728696918222032e-13, 6.720820189438925e-13, 6.671605542324377e-13, 6.616922721552898e-13, 6.60481001488189e-13, 6.660121130812324e-13, 6.870692166247028e-13, 7.090603603397694e-13, 7.100890513610236e-13, 6.904462895515606e-13, 6.702928143087483e-13, 6.646569687858428e-13, 6.632482649031324e-13, 6.631806106875693e-13, 6.63260733228116e-13, 6.608543465062844e-13, 6.647948250920743e-13, 6.659858753886583e-13, 6.665170802430676e-13, 6.637890107366595e-13, 6.621641169407555e-13, 6.615874840153191e-13, 6.606156051879031e-13, 6.626022430386569e-13, 6.679276272694712e-13, 6.719406389806004e-13, 6.716724073631275e-13, 6.681880526313022e-13, 6.64125547090999e-13, 6.645946813710335e-13, 6.612172831835239e-13, 6.662735684351273e-13, 6.714915082306483e-13, 6.7042790589944e-13, 6.651116289668746e-13, 6.617592758495494e-13, 6.683343657144791e-13, 6.831721603359209e-13, 6.811294150227409e-13, 6.678555278250009e-13, 6.631398446858838e-13, 6.66378356575098e-13, 6.642531576867006e-13, 6.617004036715834e-13, 6.616339420784101e-13, 6.666915283726205e-13, 6.614108674814212e-13, 6.693491247378169e-13, 6.78883815483089e-13, 6.780012749146858e-13, 6.685653007772185e-13, 6.620857291236848e-13, 6.632639858346334e-13, 6.706257727959186e-13, 6.730756360248669e-13, 6.648925659179239e-13, 6.625716143272842e-13, 6.684445206552037e-13, 6.726123564365638e-13, 6.652971359585869e-13, 6.613592052479023e-13, 6.702292800614407e-13, 6.849569739522665e-13, 6.832620406960199e-13, 6.674716660458324e-13, 6.616943863495262e-13, 6.755330344589139e-13, 6.892382172808686e-13, 6.888296899022761e-13, 6.796805956596486e-13, 6.730701608038958e-13, 6.694712059024388e-13, 6.735009685371329e-13, 6.895961666281147e-13]\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 9.8873e-13\n",
      "Test Loss: 9.887313407244691e-13\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n",
    "\n",
    "initial_lr = 0.0001\n",
    "\n",
    "input_sequences_reshaped = input_sequences.reshape(input_sequences.shape[0], input_sequences.shape[1], -1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(10, 50 * 50 * 6)))  # 10 for a sequence length of 10 as defined above\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=50 * 50 * 6, activation='linear'))  # output layer, linear activation\n",
    "model.add(Reshape((50, 50, 6)))\n",
    "model.compile(optimizer=Adam(learning_rate=initial_lr), loss='mse')  # compile with adam, mse\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(input_sequences_reshaped, output_values, epochs=500, batch_size=64, \n",
    "                    validation_split=0.2, callbacks=[lr_scheduler, early_stopping])\n",
    "print(\"Training Loss:\", history.history['loss'])\n",
    "\n",
    "loss = model.evaluate(input_sequences_reshaped, output_values)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

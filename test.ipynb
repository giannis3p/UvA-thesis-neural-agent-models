{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Reshape, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras.constraints import MinMaxNorm\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert .txt to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/conc_txt_test\"\n",
    "output_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data\"\n",
    "\n",
    "# create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# iterate through files in input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        try:\n",
    "            # construct input and output file paths\n",
    "            input_filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "\n",
    "            # read txt file and remove leading and trailing quotation marks from each line\n",
    "            with open(input_filepath, 'r') as file:\n",
    "                lines = [line.strip().strip('\"') for line in file.readlines()]\n",
    "\n",
    "            # remove every other line (gap lines)\n",
    "            lines = [line for index, line in enumerate(lines) if index % 2 == 0]\n",
    "\n",
    "            # check if all lines have the same number of elements\n",
    "            num_elements = len(lines[0].split(','))\n",
    "            if all(len(line.split(',')) == num_elements for line in lines):\n",
    "                # convert to df and save as csv\n",
    "                df = pd.DataFrame([line.split(',') for line in lines])\n",
    "                df.to_csv(output_filepath, index=False, header=False, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "                print(f\"Converted {input_filepath} to {output_filepath}\")\n",
    "            else:\n",
    "                print(f\"Skipping {input_filepath}: Inconsistent number of elements in lines\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {input_filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat the cytokines data to create the 'test_data_concat' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cytokine_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data\"\n",
    "output_folder = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data_concat\"\n",
    "\n",
    "def concat_files_in_folder(folder_path):\n",
    "    test_data_concat = pd.DataFrame()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_data_concat = pd.concat([test_data_concat, df])\n",
    "    return test_data_concat\n",
    "\n",
    "def sort_by_mcsteps(data):\n",
    "    return data.sort_values(by='mcsteps')\n",
    "\n",
    "concatenated_data = concat_files_in_folder(base_cytokine_folder)\n",
    "\n",
    "sorted_data = sort_by_mcsteps(concatenated_data)\n",
    "\n",
    "output_filepath = os.path.join(output_folder, \"sorted_concatenated_data.csv\")\n",
    "sorted_data.to_csv(output_filepath, index=False)\n",
    "print(f\"Sorted and concatenated data saved to: {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data for test_data_concat and drop zCOM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mcsteps  xCOM  yCOM           il8  il1  il6  il10  tnf  tgf\n",
      "0        0    33    22  3.750408e-07  0.0  0.0   0.0  0.0  0.0\n",
      "1        0    11    32  4.793328e-09  0.0  0.0   0.0  0.0  0.0\n",
      "2        0    30    35  8.997935e-09  0.0  0.0   0.0  0.0  0.0\n",
      "3        0    17    40  1.781103e-08  0.0  0.0   0.0  0.0  0.0\n",
      "4        0    21    23  4.789621e-09  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "sorted_concatenated_csv = \"C:/Users/Giannis/Documents/uva-thesis/data/test_data_concat/sorted_concatenated_data.csv\"\n",
    "data = pd.read_csv(sorted_concatenated_csv)\n",
    "data.drop(columns=['zCOM'], inplace=True)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time  xCOM  yCOM           il8           il1           il6  \\\n",
      "0         0    33    22  3.750408e-07  0.000000e+00  0.000000e+00   \n",
      "1         0    11    32  4.793328e-09  0.000000e+00  0.000000e+00   \n",
      "2         0    30    35  8.997935e-09  0.000000e+00  0.000000e+00   \n",
      "3         0    17    40  1.781103e-08  0.000000e+00  0.000000e+00   \n",
      "4         0    21    23  4.789621e-09  0.000000e+00  0.000000e+00   \n",
      "...     ...   ...   ...           ...           ...           ...   \n",
      "86155   100    49    35 -8.886183e-11  6.343394e-10  1.206925e-08   \n",
      "86156   100    36     4  1.334245e-07  1.665160e-07  1.305691e-08   \n",
      "86157   100    49    44 -1.233990e-10  1.178848e-09  1.615457e-07   \n",
      "86158   100    45    10  3.257988e-07  4.403049e-08  1.749928e-07   \n",
      "86159   100    35    38  2.107191e-05  9.170692e-08  5.693712e-19   \n",
      "\n",
      "               il10           tnf           tgf  \n",
      "0      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "1      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "2      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "3      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "4      0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "...             ...           ...           ...  \n",
      "86155  3.819835e-10  1.979543e-10  4.400244e-06  \n",
      "86156  4.469681e-10  3.720676e-07  7.833499e-06  \n",
      "86157  3.270504e-08  9.659641e-08  6.022260e-06  \n",
      "86158  3.550616e-08  1.001522e-07  6.226569e-06  \n",
      "86159  5.103635e-25  4.620498e-09  2.838544e-12  \n",
      "\n",
      "[86160 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data['time'] = (data['mcsteps'] / 10000).astype(int)\n",
    "data = data[['time'] + [col for col in data.columns if col != 'time']]\n",
    "data.drop(columns=['mcsteps'], inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cytokines\n",
    "cytokines = ['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']\n",
    "\n",
    "# get unique time values\n",
    "unique_time = data['time'].unique()\n",
    "\n",
    "arrays = {}\n",
    "\n",
    "# iterate over unique time values\n",
    "for time in unique_time:\n",
    "    # filter data for current value of time\n",
    "    data_time = data[data['time'] == time]\n",
    "    \n",
    "    # initialize 50x50x6 array for current value of time\n",
    "    array = np.zeros((50, 50, len(cytokines)))\n",
    "    \n",
    "    # get X and Y coordinates\n",
    "    x = data_time['xCOM'].astype(int)\n",
    "    y = data_time['yCOM'].astype(int)\n",
    "    \n",
    "    # get cytokine concentrations\n",
    "    concentrations = data_time[['il8', 'il1', 'il6', 'il10', 'tnf', 'tgf']].values\n",
    "    \n",
    "    # assign cytokine concentrations to corresponding position in array\n",
    "    array[x, y, :] = concentrations\n",
    "    \n",
    "    # store array for current value of time\n",
    "    arrays[time] = array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of arrays: 101\n",
      "Shape of the array: (50, 50, 6)\n",
      "Value at position (39,25): [1.7285698e-05 7.6371320e-11 2.9109778e-14 5.1850766e-18 9.9240220e-17\n",
      " 1.7688583e-11]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of arrays:\", len(arrays))\n",
    "array = arrays[91]\n",
    "print(\"Shape of the array:\", array.shape)\n",
    "print(\"Value at position (39,25):\", array[39,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read 10 sequences to predict the 11th**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "input_sequences = []\n",
    "output_values = []\n",
    "\n",
    "# convert dictionary values to a list of arrays\n",
    "arrays_list = [arrays[key] for key in sorted(arrays.keys())]\n",
    "\n",
    "# convert 'arrays' list to numpy array\n",
    "arrays_np = np.array(arrays_list)\n",
    "\n",
    "for i in range(len(arrays_np) - sequence_length):\n",
    "    input_seq = arrays_np[i:i+sequence_length]  # input sequence of arrays\n",
    "    output_val = arrays_np[i+sequence_length]   # array at next time step\n",
    "    \n",
    "    input_sequences.append(input_seq)\n",
    "    output_values.append(output_val)\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "output_values = np.array(output_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 10, 50, 50, 6)\n",
      "(91, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences.shape)\n",
    "print(output_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n",
    "\n",
    "initial_lr = 0.0001\n",
    "\n",
    "input_sequences_reshaped = input_sequences.reshape(input_sequences.shape[0], input_sequences.shape[1], -1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(10, 50 * 50 * 6)))  # 10 for a sequence length of 10 as defined above\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=50 * 50 * 6, activation='linear'))  # output layer, linear activation\n",
    "model.add(Reshape((50, 50, 6)))\n",
    "model.compile(optimizer=Adam(learning_rate=initial_lr), loss='mse')  # compile with adam, mse\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(input_sequences_reshaped, output_values, epochs=500, batch_size=64, \n",
    "                    validation_split=0.2, callbacks=[lr_scheduler, early_stopping])\n",
    "print(\"Training Loss:\", history.history['loss'])\n",
    "\n",
    "loss = model.evaluate(input_sequences_reshaped, output_values)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stalstm_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              multiple                  3856640   \n",
      "                                                                 \n",
      " spatial_temporal_attention_  multiple                 964289    \n",
      " 18 (SpatialTemporalAttentio                                     \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_107 (Dense)           multiple                  3250      \n",
      "                                                                 \n",
      " dense_108 (Dense)           multiple                  2550      \n",
      "                                                                 \n",
      " dense_109 (Dense)           multiple                  765000    \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,591,729\n",
      "Trainable params: 5,591,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.9475e-12 - val_loss: 1.1562e-11 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 4.9113e-12 - val_loss: 1.1482e-11 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 4.8604e-12 - val_loss: 1.1386e-11 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.7987e-12 - val_loss: 1.1275e-11 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 4.7283e-12 - val_loss: 1.1152e-11 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 4.6507e-12 - val_loss: 1.1019e-11 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 4.5670e-12 - val_loss: 1.0878e-11 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 4.4782e-12 - val_loss: 1.0729e-11 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 4.3850e-12 - val_loss: 1.0573e-11 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 4.2881e-12 - val_loss: 1.0411e-11 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.1881e-12 - val_loss: 1.0244e-11 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.0856e-12 - val_loss: 1.0073e-11 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 3.9811e-12 - val_loss: 9.8989e-12 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.8750e-12 - val_loss: 9.7213e-12 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.7679e-12 - val_loss: 9.5414e-12 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 3.6600e-12 - val_loss: 9.3595e-12 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 3.5518e-12 - val_loss: 9.1763e-12 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 3.4436e-12 - val_loss: 8.9923e-12 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.3358e-12 - val_loss: 8.8079e-12 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 3.2286e-12 - val_loss: 8.6234e-12 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.1223e-12 - val_loss: 8.4394e-12 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.0172e-12 - val_loss: 8.2561e-12 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.9136e-12 - val_loss: 8.0740e-12 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.8116e-12 - val_loss: 7.8932e-12 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.7115e-12 - val_loss: 7.7142e-12 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.6134e-12 - val_loss: 7.5372e-12 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.5174e-12 - val_loss: 7.3624e-12 - lr: 1.0000e-04\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.4238e-12 - val_loss: 7.1901e-12 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.3326e-12 - val_loss: 7.0205e-12 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 2.2440e-12 - val_loss: 6.8538e-12 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.1581e-12 - val_loss: 6.6901e-12 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.0748e-12 - val_loss: 6.5296e-12 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.9944e-12 - val_loss: 6.3725e-12 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.9168e-12 - val_loss: 6.2188e-12 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.8420e-12 - val_loss: 6.0687e-12 - lr: 1.0000e-04\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7702e-12 - val_loss: 5.9223e-12 - lr: 1.0000e-04\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.7013e-12 - val_loss: 5.7795e-12 - lr: 1.0000e-04\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 1.6352e-12 - val_loss: 5.6405e-12 - lr: 1.0000e-04\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.5721e-12 - val_loss: 5.5054e-12 - lr: 1.0000e-04\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5118e-12 - val_loss: 5.3741e-12 - lr: 1.0000e-04\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4543e-12 - val_loss: 5.2466e-12 - lr: 1.0000e-04\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.3996e-12 - val_loss: 5.1230e-12 - lr: 1.0000e-04\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.3477e-12 - val_loss: 5.0032e-12 - lr: 1.0000e-04\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2985e-12 - val_loss: 4.8873e-12 - lr: 1.0000e-04\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.2518e-12 - val_loss: 4.7753e-12 - lr: 1.0000e-04\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2078e-12 - val_loss: 4.6670e-12 - lr: 1.0000e-04\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.1662e-12 - val_loss: 4.5624e-12 - lr: 1.0000e-04\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1271e-12 - val_loss: 4.4616e-12 - lr: 1.0000e-04\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0903e-12 - val_loss: 4.3644e-12 - lr: 1.0000e-04\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0558e-12 - val_loss: 4.2708e-12 - lr: 1.0000e-04\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0234e-12 - val_loss: 4.1807e-12 - lr: 1.0000e-04\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 9.9311e-13 - val_loss: 4.0941e-12 - lr: 1.0000e-04\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.6483e-13 - val_loss: 4.0108e-12 - lr: 1.0000e-04\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.3848e-13 - val_loss: 3.9309e-12 - lr: 1.0000e-04\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.1395e-13 - val_loss: 3.8542e-12 - lr: 1.0000e-04\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 8.9117e-13 - val_loss: 3.7806e-12 - lr: 1.0000e-04\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 8.7004e-13 - val_loss: 3.7102e-12 - lr: 1.0000e-04\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.5049e-13 - val_loss: 3.6427e-12 - lr: 1.0000e-04\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.3243e-13 - val_loss: 3.5781e-12 - lr: 1.0000e-04\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 8.1578e-13 - val_loss: 3.5163e-12 - lr: 1.0000e-04\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 8.0044e-13 - val_loss: 3.4573e-12 - lr: 1.0000e-04\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.8636e-13 - val_loss: 3.4009e-12 - lr: 1.0000e-04\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 7.7345e-13 - val_loss: 3.3471e-12 - lr: 1.0000e-04\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 7.6164e-13 - val_loss: 3.2957e-12 - lr: 1.0000e-04\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.5085e-13 - val_loss: 3.2468e-12 - lr: 1.0000e-04\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 7.4102e-13 - val_loss: 3.2002e-12 - lr: 1.0000e-04\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 7.3207e-13 - val_loss: 3.1558e-12 - lr: 1.0000e-04\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.2396e-13 - val_loss: 3.1136e-12 - lr: 1.0000e-04\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 7.1662e-13 - val_loss: 3.0734e-12 - lr: 1.0000e-04\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 7.0998e-13 - val_loss: 3.0352e-12 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 7.0400e-13 - val_loss: 2.9990e-12 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.9862e-13 - val_loss: 2.9646e-12 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.9380e-13 - val_loss: 2.9320e-12 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.8949e-13 - val_loss: 2.9011e-12 - lr: 1.0000e-04\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 6.8564e-13 - val_loss: 2.8719e-12 - lr: 1.0000e-04\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.8222e-13 - val_loss: 2.8442e-12 - lr: 1.0000e-04\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.7918e-13 - val_loss: 2.8180e-12 - lr: 1.0000e-04\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.7649e-13 - val_loss: 2.7933e-12 - lr: 1.0000e-04\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 6.7412e-13 - val_loss: 2.7700e-12 - lr: 1.0000e-04\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 6.7204e-13 - val_loss: 2.7479e-12 - lr: 1.0000e-04\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 6.7022e-13 - val_loss: 2.7272e-12 - lr: 1.0000e-04\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.6862e-13 - val_loss: 2.7077e-12 - lr: 1.0000e-04\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.6724e-13 - val_loss: 2.6893e-12 - lr: 1.0000e-04\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.6604e-13 - val_loss: 2.6721e-12 - lr: 1.0000e-04\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.6501e-13 - val_loss: 2.6559e-12 - lr: 1.0000e-04\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.6413e-13 - val_loss: 2.6408e-12 - lr: 1.0000e-04\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 6.6337e-13 - val_loss: 2.6266e-12 - lr: 1.0000e-04\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 6.6273e-13 - val_loss: 2.6133e-12 - lr: 1.0000e-04\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.6219e-13 - val_loss: 2.6009e-12 - lr: 1.0000e-04\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.6174e-13 - val_loss: 2.5894e-12 - lr: 1.0000e-04\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 6.6136e-13 - val_loss: 2.5786e-12 - lr: 1.0000e-04\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.6105e-13 - val_loss: 2.5686e-12 - lr: 1.0000e-04\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 6.6080e-13 - val_loss: 2.5593e-12 - lr: 1.0000e-04\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 6.6060e-13 - val_loss: 2.5507e-12 - lr: 1.0000e-04\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 6.6043e-13 - val_loss: 2.5428e-12 - lr: 1.0000e-04\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.6031e-13 - val_loss: 2.5355e-12 - lr: 1.0000e-04\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.6021e-13 - val_loss: 2.5287e-12 - lr: 1.0000e-04\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.6013e-13 - val_loss: 2.5226e-12 - lr: 1.0000e-04\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 6.6008e-13 - val_loss: 2.5169e-12 - lr: 1.0000e-04\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.6004e-13 - val_loss: 2.5117e-12 - lr: 1.0000e-04\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 6.6001e-13 - val_loss: 2.4651e-12 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 6.6024e-13 - val_loss: 2.4252e-12 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.6110e-13 - val_loss: 2.3928e-12 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.6227e-13 - val_loss: 2.3683e-12 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.6343e-13 - val_loss: 2.3519e-12 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.6435e-13 - val_loss: 2.3433e-12 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 6.6487e-13 - val_loss: 2.3421e-12 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.6493e-13 - val_loss: 2.3476e-12 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.6456e-13 - val_loss: 2.3591e-12 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.6386e-13 - val_loss: 2.3755e-12 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.6296e-13 - val_loss: 2.3959e-12 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.6201e-13 - val_loss: 2.4189e-12 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.6114e-13 - val_loss: 2.4436e-12 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.6045e-13 - val_loss: 2.4686e-12 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.6000e-13 - val_loss: 2.4929e-12 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.5979e-13 - val_loss: 2.5155e-12 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.5980e-13 - val_loss: 2.5355e-12 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 6.5995e-13 - val_loss: 2.5522e-12 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.6019e-13 - val_loss: 2.5652e-12 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.6045e-13 - val_loss: 2.5741e-12 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.6066e-13 - val_loss: 2.5789e-12 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.6077e-13 - val_loss: 2.5797e-12 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.6079e-13 - val_loss: 2.5769e-12 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 6.6071e-13 - val_loss: 2.5710e-12 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.6055e-13 - val_loss: 2.5624e-12 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.6035e-13 - val_loss: 2.5520e-12 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.6014e-13 - val_loss: 2.5402e-12 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.5996e-13 - val_loss: 2.5279e-12 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.5981e-13 - val_loss: 2.5157e-12 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 6.5972e-13 - val_loss: 2.5040e-12 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.5969e-13 - val_loss: 2.4935e-12 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5970e-13 - val_loss: 2.4844e-12 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.5975e-13 - val_loss: 2.4770e-12 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 6.5980e-13 - val_loss: 2.4716e-12 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.5986e-13 - val_loss: 2.4681e-12 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5990e-13 - val_loss: 2.4666e-12 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.5992e-13 - val_loss: 2.4669e-12 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 6.5991e-13 - val_loss: 2.4689e-12 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.5989e-13 - val_loss: 2.4722e-12 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5985e-13 - val_loss: 2.4767e-12 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5980e-13 - val_loss: 2.4819e-12 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.5975e-13 - val_loss: 2.4876e-12 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 6.5972e-13 - val_loss: 2.4935e-12 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.5969e-13 - val_loss: 2.4993e-12 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 6.5968e-13 - val_loss: 2.5046e-12 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.5967e-13 - val_loss: 2.5093e-12 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.5968e-13 - val_loss: 2.5132e-12 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.5969e-13 - val_loss: 2.5162e-12 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 6.5971e-13 - val_loss: 2.5182e-12 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.5972e-13 - val_loss: 2.5192e-12 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5972e-13 - val_loss: 2.5193e-12 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5972e-13 - val_loss: 2.5184e-12 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.5971e-13 - val_loss: 2.5169e-12 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 6.5971e-13 - val_loss: 2.5147e-12 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 6.5969e-13 - val_loss: 2.5121e-12 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5968e-13 - val_loss: 2.5093e-12 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.5967e-13 - val_loss: 2.5064e-12 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5966e-13 - val_loss: 2.5036e-12 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.5966e-13 - val_loss: 2.5009e-12 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.5966e-13 - val_loss: 2.4986e-12 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 6.5966e-13 - val_loss: 2.4967e-12 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.5966e-13 - val_loss: 2.4953e-12 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.5967e-13 - val_loss: 2.4943e-12 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.5967e-13 - val_loss: 2.4939e-12 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 6.5967e-13 - val_loss: 2.4939e-12 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.5967e-13 - val_loss: 2.4944e-12 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.5967e-13 - val_loss: 2.4952e-12 - lr: 0.0010\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.5966e-13 - val_loss: 2.4963e-12 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 6.5966e-13 - val_loss: 2.4976e-12 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.5965e-13 - val_loss: 2.4990e-12 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.5965e-13 - val_loss: 2.5004e-12 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.5964e-13 - val_loss: 2.5018e-12 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.5964e-13 - val_loss: 2.5031e-12 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.5964e-13 - val_loss: 2.5042e-12 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 6.5964e-13 - val_loss: 2.5051e-12 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 6.5964e-13 - val_loss: 2.5057e-12 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.5964e-13 - val_loss: 2.5061e-12 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 6.5964e-13 - val_loss: 2.5063e-12 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.5964e-13 - val_loss: 2.5062e-12 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.5963e-13 - val_loss: 2.5059e-12 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.5963e-13 - val_loss: 2.5054e-12 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.5963e-13 - val_loss: 2.5048e-12 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 6.5963e-13 - val_loss: 2.5041e-12 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 6.5963e-13 - val_loss: 2.5034e-12 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5963e-13 - val_loss: 2.5027e-12 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.5963e-13 - val_loss: 2.5020e-12 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 6.5963e-13 - val_loss: 2.5014e-12 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 6.5963e-13 - val_loss: 2.5009e-12 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.5963e-13 - val_loss: 2.5005e-12 - lr: 0.0010\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5963e-13 - val_loss: 2.5002e-12 - lr: 0.0010\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.5963e-13 - val_loss: 2.5001e-12 - lr: 0.0010\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.5963e-13 - val_loss: 2.5001e-12 - lr: 0.0010\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 6.5963e-13 - val_loss: 2.5002e-12 - lr: 0.0010\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5963e-13 - val_loss: 2.5005e-12 - lr: 0.0010\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 6.5963e-13 - val_loss: 2.5008e-12 - lr: 0.0010\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 6.5963e-13 - val_loss: 2.5011e-12 - lr: 0.0010\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5963e-13 - val_loss: 2.5015e-12 - lr: 0.0010\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.5963e-13 - val_loss: 2.5018e-12 - lr: 0.0010\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 6.5963e-13 - val_loss: 2.5022e-12 - lr: 0.0010\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.5963e-13 - val_loss: 2.5025e-12 - lr: 0.0010\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 6.5963e-13 - val_loss: 2.5028e-12 - lr: 0.0010\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 6.5963e-13 - val_loss: 2.5030e-12 - lr: 0.0010\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.5963e-13 - val_loss: 2.5031e-12 - lr: 0.0010\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 6.5963e-13 - val_loss: 2.5032e-12 - lr: 0.0010\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.5963e-13 - val_loss: 2.5032e-12 - lr: 0.0010\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 6.5963e-13 - val_loss: 2.5032e-12 - lr: 0.0010\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5963e-13Restoring model weights from the end of the best epoch: 107.\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.5963e-13 - val_loss: 2.5031e-12 - lr: 0.0010\n",
      "Epoch 207: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0151e-12\n",
      "Test Loss: 1.015100221761489e-12\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 100:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n",
    "\n",
    "class SpatialTemporalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SpatialTemporalAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_s = tf.keras.layers.Dense(hidden_size)\n",
    "        self.W_t = tf.keras.layers.Dense(hidden_size)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, lstm_output, input_data):\n",
    "        # attention weights\n",
    "        spatial_attention = tf.tanh(self.W_s(lstm_output))\n",
    "        temporal_attention = tf.tanh(self.W_t(input_data))\n",
    "        attention_scores = self.V(spatial_attention * temporal_attention)\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=1)\n",
    "        \n",
    "        # apply attention to LSTM output\n",
    "        attended_output = tf.matmul(tf.transpose(attention_weights, [0, 2, 1]), lstm_output)\n",
    "        return attended_output\n",
    "\n",
    "class STALSTM(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, input_shape):\n",
    "        super(STALSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.attention = SpatialTemporalAttention(hidden_size)\n",
    "        self.fc1 = tf.keras.layers.Dense(50, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(50, activation='relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(tf.reduce_prod(input_shape[1:]), activation='linear')  # adjust output size\n",
    "        self.reshape = tf.keras.layers.Reshape(input_shape[1:])  # reshape to match output shape\n",
    "        self.input_shape_model = input_shape\n",
    "\n",
    "    def call(self, input_data):\n",
    "        lstm_output = self.lstm(input_data)\n",
    "        attended_output = self.attention(lstm_output, input_data)\n",
    "        x = tf.reshape(attended_output, (-1, self.hidden_size))  # flatten for fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.fc3(x)\n",
    "        output = self.reshape(output)  # reshape to match input shape\n",
    "        return output\n",
    "\n",
    "# reshape input sequences\n",
    "input_sequences_reshaped = input_sequences.reshape(input_sequences.shape[0], input_sequences.shape[1], -1)\n",
    "\n",
    "input_shape = input_sequences.shape[1:]\n",
    "model = STALSTM(hidden_size=64, input_shape=input_shape)\n",
    "\n",
    "# build the model by calling it on a batch of data\n",
    "sample_input = tf.convert_to_tensor(input_sequences_reshaped[:1])  # take a sample batch\n",
    "_ = model(sample_input)  # calling the model on a sample input to build it\n",
    "\n",
    "initial_lr = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr), loss='mse')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# custom MSE loss function\n",
    "def custom_mse(y_true, y_pred):\n",
    "    # reshape y_pred to match the shape of y_true\n",
    "    y_pred = tf.reshape(y_pred, (-1,) + y_true.shape[1:])\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# train\n",
    "history = model.fit(input_sequences_reshaped, output_values, epochs=500, batch_size=128, \n",
    "                    validation_split=0.2, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "# evaluate\n",
    "loss = model.evaluate(input_sequences_reshaped, output_values)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Giannis\\Documents\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 9s 4s/step - loss: 0.0655 - val_loss: 0.2007 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0650 - val_loss: 0.1993 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0643 - val_loss: 0.1966 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0632 - val_loss: 0.1924 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0613 - val_loss: 0.1867 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0590 - val_loss: 0.1800 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0562 - val_loss: 0.1735 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0532 - val_loss: 0.1676 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0502 - val_loss: 0.1624 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0474 - val_loss: 0.1578 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0451 - val_loss: 0.1537 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0430 - val_loss: 0.1503 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0412 - val_loss: 0.1474 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0395 - val_loss: 0.1449 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 194ms/step - loss: 0.0380 - val_loss: 0.1428 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0367 - val_loss: 0.1408 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0355 - val_loss: 0.1389 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0344 - val_loss: 0.1368 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0334 - val_loss: 0.1348 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0325 - val_loss: 0.1330 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0317 - val_loss: 0.1314 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0309 - val_loss: 0.1301 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0302 - val_loss: 0.1288 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0295 - val_loss: 0.1276 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0289 - val_loss: 0.1264 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.0284 - val_loss: 0.1254 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0279 - val_loss: 0.1243 - lr: 1.0000e-04\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 11s 5s/step - loss: 0.0274 - val_loss: 0.1231 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 202ms/step - loss: 0.0269 - val_loss: 0.1221 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 3s 823ms/step - loss: 0.0265 - val_loss: 0.1212 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.0261 - val_loss: 0.1204 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 5s 3s/step - loss: 0.0257 - val_loss: 0.1198 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0254 - val_loss: 0.1192 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0251 - val_loss: 0.1187 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0248 - val_loss: 0.1181 - lr: 1.0000e-04\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0245 - val_loss: 0.1175 - lr: 1.0000e-04\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0242 - val_loss: 0.1168 - lr: 1.0000e-04\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0239 - val_loss: 0.1162 - lr: 1.0000e-04\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0236 - val_loss: 0.1154 - lr: 1.0000e-04\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0234 - val_loss: 0.1149 - lr: 1.0000e-04\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0232 - val_loss: 0.1145 - lr: 1.0000e-04\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0229 - val_loss: 0.1141 - lr: 1.0000e-04\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0227 - val_loss: 0.1135 - lr: 1.0000e-04\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0225 - val_loss: 0.1128 - lr: 1.0000e-04\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0223 - val_loss: 0.1121 - lr: 1.0000e-04\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0221 - val_loss: 0.1115 - lr: 1.0000e-04\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0219 - val_loss: 0.1109 - lr: 1.0000e-04\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0217 - val_loss: 0.1105 - lr: 1.0000e-04\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0215 - val_loss: 0.1099 - lr: 1.0000e-04\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 196ms/step - loss: 0.0214 - val_loss: 0.1094 - lr: 1.0000e-04\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0212 - val_loss: 0.1090 - lr: 1.0000e-04\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0210 - val_loss: 0.1086 - lr: 1.0000e-04\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0209 - val_loss: 0.1082 - lr: 1.0000e-04\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0207 - val_loss: 0.1079 - lr: 1.0000e-04\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0206 - val_loss: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0204 - val_loss: 0.1076 - lr: 1.0000e-04\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0203 - val_loss: 0.1073 - lr: 1.0000e-04\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0201 - val_loss: 0.1071 - lr: 1.0000e-04\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0200 - val_loss: 0.1069 - lr: 1.0000e-04\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.0199 - val_loss: 0.1066 - lr: 1.0000e-04\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 185ms/step - loss: 0.0198 - val_loss: 0.1063 - lr: 1.0000e-04\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.0197 - val_loss: 0.1060 - lr: 1.0000e-04\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 2s 813ms/step - loss: 0.0195 - val_loss: 0.1056 - lr: 1.0000e-04\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0194 - val_loss: 0.1052 - lr: 1.0000e-04\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.0193 - val_loss: 0.1048 - lr: 1.0000e-04\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 0.0193 - val_loss: 0.1045 - lr: 1.0000e-04\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0192 - val_loss: 0.1044 - lr: 1.0000e-04\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0191 - val_loss: 0.1042 - lr: 1.0000e-04\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 1s 652ms/step - loss: 0.0190 - val_loss: 0.1039 - lr: 1.0000e-04\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0189 - val_loss: 0.1035 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0188 - val_loss: 0.1031 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 2s 154ms/step - loss: 0.0187 - val_loss: 0.1028 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 18s 9s/step - loss: 0.0187 - val_loss: 0.1024 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0186 - val_loss: 0.1020 - lr: 1.0000e-04\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0185 - val_loss: 0.1018 - lr: 1.0000e-04\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 1s 164ms/step - loss: 0.0185 - val_loss: 0.1015 - lr: 1.0000e-04\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 0.0184 - val_loss: 0.1012 - lr: 1.0000e-04\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 0.0184 - val_loss: 0.1010 - lr: 1.0000e-04\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.0183 - val_loss: 0.1009 - lr: 1.0000e-04\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 0.0182 - val_loss: 0.1007 - lr: 1.0000e-04\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0182 - val_loss: 0.1005 - lr: 1.0000e-04\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0181 - val_loss: 0.1004 - lr: 1.0000e-04\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0181 - val_loss: 0.1002 - lr: 1.0000e-04\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0180 - val_loss: 0.1000 - lr: 1.0000e-04\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0180 - val_loss: 0.0998 - lr: 1.0000e-04\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0179 - val_loss: 0.0996 - lr: 1.0000e-04\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 0.0179 - val_loss: 0.0995 - lr: 1.0000e-04\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 2s 126ms/step - loss: 0.0178 - val_loss: 0.0995 - lr: 1.0000e-04\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.0178 - val_loss: 0.0995 - lr: 1.0000e-04\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 26s 133ms/step - loss: 0.0177 - val_loss: 0.0995 - lr: 1.0000e-04\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0177 - val_loss: 0.0994 - lr: 1.0000e-04\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 4s 862ms/step - loss: 0.0176 - val_loss: 0.0992 - lr: 1.0000e-04\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0176 - val_loss: 0.0990 - lr: 1.0000e-04\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.0176 - val_loss: 0.0989 - lr: 1.0000e-04\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 18s 9s/step - loss: 0.0175 - val_loss: 0.0987 - lr: 1.0000e-04\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 3s 2s/step - loss: 0.0175 - val_loss: 0.0985 - lr: 1.0000e-04\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 2s 939ms/step - loss: 0.0175 - val_loss: 0.0983 - lr: 1.0000e-04\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 20s 10s/step - loss: 0.0174 - val_loss: 0.0981 - lr: 1.0000e-04\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 10s 5s/step - loss: 0.0174 - val_loss: 0.0981 - lr: 1.0000e-04\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0174 - val_loss: 0.0980 - lr: 1.0000e-04\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.0175 - val_loss: 0.0963 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 16s 8s/step - loss: 0.0203 - val_loss: 0.1034 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 9s 5s/step - loss: 0.0216 - val_loss: 0.1166 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0225 - val_loss: 0.1134 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 4s 161ms/step - loss: 0.0207 - val_loss: 0.1109 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 15s 7s/step - loss: 0.0199 - val_loss: 0.1073 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 3s 2s/step - loss: 0.0189 - val_loss: 0.1024 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 17s 8s/step - loss: 0.0183 - val_loss: 0.0991 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0180 - val_loss: 0.0976 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0177 - val_loss: 0.0967 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0175 - val_loss: 0.0958 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0174 - val_loss: 0.0952 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0172 - val_loss: 0.0949 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0170 - val_loss: 0.0944 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0169 - val_loss: 0.0941 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0167 - val_loss: 0.0945 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0167 - val_loss: 0.0948 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0166 - val_loss: 0.0946 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0165 - val_loss: 0.0945 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0164 - val_loss: 0.0940 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0162 - val_loss: 0.0937 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0162 - val_loss: 0.0934 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0161 - val_loss: 0.0928 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0160 - val_loss: 0.0926 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0159 - val_loss: 0.0926 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0158 - val_loss: 0.0925 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 4s 120ms/step - loss: 0.0158 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0157 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0156 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0156 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 1s 138ms/step - loss: 0.0156 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0154 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 1s 689ms/step - loss: 0.0154 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 0.0154 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 0.0153 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 1s 117ms/step - loss: 0.0153 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 0.0152 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0151 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0150 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0150 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0150 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0149 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0148 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 24s 12s/step - loss: 0.0148 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0147 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0146 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0145 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0145 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0145 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0144 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0143 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0143 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0143 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0142 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0141 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0141 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0140 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0139 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0139 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0138 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0138 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0137 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0137 - val_loss: 0.0911 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.0136 - val_loss: 0.0911 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0135 - val_loss: 0.0911 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.0135 - val_loss: 0.0910 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 1s 319ms/step - loss: 0.0135 - val_loss: 0.0910 - lr: 0.0010\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0134 - val_loss: 0.0911 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 20s 461ms/step - loss: 0.0134 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.0133 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 1s 307ms/step - loss: 0.0132 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 12s 6s/step - loss: 0.0132 - val_loss: 0.0911 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 1s 296ms/step - loss: 0.0131 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0131 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0130 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 0.0130 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0129 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 7s 126ms/step - loss: 0.0129 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0128 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0128 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0127 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0127 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0126 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0125 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0125 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0125 - val_loss: 0.0912 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0124 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0123 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0123 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.0122 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0122 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0121 - val_loss: 0.0913 - lr: 0.0010\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0121 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0120 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 8s 4s/step - loss: 0.0119 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 1s 157ms/step - loss: 0.0118 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 8s 4s/step - loss: 0.0118 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0117 - val_loss: 0.0914 - lr: 0.0010\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 1s 644ms/step - loss: 0.0117 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0116 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 1s 265ms/step - loss: 0.0115 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 1s 134ms/step - loss: 0.0115 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0114 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0114 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0114 - val_loss: 0.0915 - lr: 0.0010\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 8s 123ms/step - loss: 0.0113 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 1s 531ms/step - loss: 0.0112 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 2s 816ms/step - loss: 0.0111 - val_loss: 0.0916 - lr: 0.0010\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.0111 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 14s 7s/step - loss: 0.0110 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 9s 4s/step - loss: 0.0110 - val_loss: 0.0917 - lr: 0.0010\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 9s 4s/step - loss: 0.0109 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0109 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0108 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 1s 683ms/step - loss: 0.0108 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0107 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 2s 1s/step - loss: 0.0107 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.0106 - val_loss: 0.0918 - lr: 0.0010\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0106 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0105 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0105 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 17s 8s/step - loss: 0.0104 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0104 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0103 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0103 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 8s 4s/step - loss: 0.0102 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 9s 4s/step - loss: 0.0102 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 0.0101 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0101 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0100 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 1s 362ms/step - loss: 0.0100 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0099 - val_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 5s 3s/step - loss: 0.0099 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0099 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0098 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0098 - val_loss: 0.0924 - lr: 0.0010\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0097 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0097 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0096 - val_loss: 0.0922 - lr: 0.0010\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0095 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0095 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0094 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0094 - val_loss: 0.0921 - lr: 0.0010\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0093 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0093 - val_loss: 0.0924 - lr: 0.0010\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0092 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0092 - val_loss: 0.0924 - lr: 0.0010\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0092 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0091 - val_loss: 0.0923 - lr: 0.0010\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0091 - val_loss: 0.0926 - lr: 0.0010\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0090 - val_loss: 0.0929 - lr: 0.0010\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0090 - val_loss: 0.0929 - lr: 0.0010\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0089 - val_loss: 0.0926 - lr: 0.0010\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0089 - val_loss: 0.0928 - lr: 0.0010\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0088 - val_loss: 0.0926 - lr: 0.0010\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0088 - val_loss: 0.0928 - lr: 0.0010\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0088 - val_loss: 0.0927 - lr: 0.0010\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0087 - val_loss: 0.0925 - lr: 0.0010\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0087 - val_loss: 0.0929 - lr: 0.0010\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0086 - val_loss: 0.0932 - lr: 0.0010\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0086 - val_loss: 0.0931 - lr: 0.0010\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0085 - val_loss: 0.0932 - lr: 0.0010\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0085 - val_loss: 0.0932 - lr: 0.0010\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0084 - val_loss: 0.0925 - lr: 0.0010\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0084 - val_loss: 0.0927 - lr: 0.0010\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0083 - val_loss: 0.0930 - lr: 0.0010\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0296\n",
      "3/3 [==============================] - 0s 41ms/step\n",
      "Cytokine Concentrations MSE: 1.6176819588031966e-05\n",
      "Cytokine Concentrations MAE: 0.001510205809554016\n"
     ]
    }
   ],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    if epoch < 100:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 1e-3\n",
    "\n",
    "scaler_input = MinMaxScaler()\n",
    "input_sequences_scaled = scaler_input.fit_transform(input_sequences.reshape(-1, sequence_length * 50 * 50 * 6))\n",
    "input_sequences_scaled = input_sequences_scaled.reshape(-1, sequence_length, 50, 50, 6)\n",
    "\n",
    "scaler_output = MinMaxScaler()\n",
    "output_values_scaled = scaler_output.fit_transform(output_values.reshape(-1, 50 * 50 * 6))\n",
    "output_values_scaled = output_values_scaled.reshape(-1, 50, 50, 6)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(sequence_length, 50, 50, 6)),\n",
    "    Reshape((sequence_length, -1)),\n",
    "    LSTM(units=64, return_sequences=False),\n",
    "    Dense(units=50*50*6, activation='linear'),\n",
    "    Reshape((50, 50, 6))\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "history = model.fit(input_sequences_scaled, output_values_scaled, validation_split=0.2, epochs=500, batch_size=32, callbacks=[early_stopping, lr_scheduler_callback])\n",
    "\n",
    "loss = model.evaluate(input_sequences_scaled, output_values_scaled)\n",
    "\n",
    "predictions_scaled = model.predict(input_sequences_scaled)\n",
    "\n",
    "predictions = scaler_output.inverse_transform(predictions_scaled.reshape(-1, 50 * 50 * 6))\n",
    "predictions = predictions.reshape(-1, 50, 50, 6)\n",
    "\n",
    "true_cytokine_concentrations = output_values[:, :, :, :6]\n",
    "predicted_cytokine_concentrations = predictions[:, :, :, :6]\n",
    "\n",
    "cytokine_mse = mean_squared_error(true_cytokine_concentrations.flatten(), predicted_cytokine_concentrations.flatten())\n",
    "cytokine_mae = mean_absolute_error(true_cytokine_concentrations.flatten(), predicted_cytokine_concentrations.flatten())\n",
    "\n",
    "print(\"Cytokine Concentrations MSE:\", cytokine_mse)\n",
    "print(\"Cytokine Concentrations MAE:\", cytokine_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

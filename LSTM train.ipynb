{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert .txt to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/concentrations_txt/S8\"\n",
    "output_folder = \"C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/concentrations/S8\"\n",
    "\n",
    "# create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# iterate through files in input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        try:\n",
    "            # construct input and output file paths\n",
    "            input_filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, os.path.splitext(filename)[0] + \".csv\")\n",
    "\n",
    "            # read txt file and remove leading and trailing quotation marks from each line\n",
    "            with open(input_filepath, 'r') as file:\n",
    "                lines = [line.strip().strip('\"') for line in file.readlines()]\n",
    "\n",
    "            # convert to df and save as csv\n",
    "            df = pd.DataFrame([line.split(',') for line in lines])\n",
    "            df.to_csv(output_filepath, index=False, header=False, quoting=csv.QUOTE_NONE, escapechar=' ')\n",
    "            print(f\"Converted {input_filepath} to {output_filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {input_filepath}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge data in batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S1.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (74758, 10)\n",
      "Merged data shape: (74758, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_1.csv\n",
      "Processing batch 2\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S2.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (83259, 10)\n",
      "Merged data shape: (83259, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_2.csv\n",
      "Processing batch 3\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S3.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (123611, 10)\n",
      "Merged data shape: (123611, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_3.csv\n",
      "Processing batch 4\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S4.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (174195, 10)\n",
      "Merged data shape: (174195, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_4.csv\n",
      "Processing batch 5\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S5.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (274522, 10)\n",
      "Merged data shape: (274522, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_5.csv\n",
      "Processing batch 6\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S6.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (371380, 10)\n",
      "Merged data shape: (371380, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_6.csv\n",
      "Processing batch 7\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S7.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (469718, 10)\n",
      "Merged data shape: (469718, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_7.csv\n",
      "Processing batch 8\n",
      "Cellcounts file: C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts\\cellcount S8.csv\n",
      "Cellcounts batch shape: (101, 11)\n",
      "Cytokine batch shape: (569275, 10)\n",
      "Merged data shape: (569275, 20)\n",
      "Saved merged data to C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data\\combined_data_batch_8.csv\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "cellcounts_folder = 'C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/cellcounts'\n",
    "base_cytokine_folder = 'C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/concentrations'\n",
    "output_folder = 'C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Define batch size\n",
    "cellcounts_batch_size = 8\n",
    "cytokine_batch_size = 101\n",
    "\n",
    "# Iterate over batches\n",
    "for batch_index in range(1, cellcounts_batch_size + 1):\n",
    "    print(f\"Processing batch {batch_index}\")\n",
    "\n",
    "    # Get cellcounts file for the current batch\n",
    "    cellcounts_file = os.path.join(cellcounts_folder, f'cellcount S{batch_index}.csv')\n",
    "    print(\"Cellcounts file:\", cellcounts_file)\n",
    "\n",
    "    # Get cytokine subfolder for the current batch\n",
    "    cytokine_subfolder = f'S{batch_index}'\n",
    "    cytokine_folder = os.path.join(base_cytokine_folder, cytokine_subfolder)\n",
    "\n",
    "    # Read cellcounts data\n",
    "    df_cellcounts_batch = pd.read_csv(cellcounts_file)\n",
    "    print(\"Cellcounts batch shape:\", df_cellcounts_batch.shape)\n",
    "\n",
    "    # Initialize an empty DataFrame to store cytokine data\n",
    "    df_cytokine_batch = pd.DataFrame()\n",
    "\n",
    "    # Iterate over cytokine files in the subfolder\n",
    "    for cytokine_file in os.listdir(cytokine_folder):\n",
    "        if cytokine_file.endswith('.csv'):\n",
    "            file_path = os.path.join(cytokine_folder, cytokine_file)\n",
    "            df_cytokine = pd.read_csv(file_path)\n",
    "            df_cytokine_batch = pd.concat([df_cytokine_batch, df_cytokine], ignore_index=True)\n",
    "\n",
    "    print(\"Cytokine batch shape:\", df_cytokine_batch.shape)\n",
    "\n",
    "    # Merge cellcounts and cytokine data\n",
    "    merged_data = pd.merge(df_cellcounts_batch, df_cytokine_batch, on='mcsteps')\n",
    "    print(\"Merged data shape:\", merged_data.shape)\n",
    "\n",
    "    # Save merged data to a new CSV file\n",
    "    output_filename = os.path.join(output_folder, f'combined_data_batch_{batch_index}.csv')\n",
    "    merged_data.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved merged data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data to cover all initializations and drop zCOM column as we have 2D spatial data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74758, 19)\n",
      "   mcsteps     1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "1        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "2        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "3        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "4        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0    84   376  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   432   181  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   409   105  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   247   394  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   132   141  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(83259, 19)\n",
      "   mcsteps      1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  100.0  1072.0  969.0  110.0  26.0  0.0  125.0  0.0  0.0  28.0   \n",
      "1        0  100.0  1072.0  969.0  110.0  26.0  0.0  125.0  0.0  0.0  28.0   \n",
      "2        0  100.0  1072.0  969.0  110.0  26.0  0.0  125.0  0.0  0.0  28.0   \n",
      "3        0  100.0  1072.0  969.0  110.0  26.0  0.0  125.0  0.0  0.0  28.0   \n",
      "4        0  100.0  1072.0  969.0  110.0  26.0  0.0  125.0  0.0  0.0  28.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0   170    80  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   217   214  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   289   163  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   413   269  8.549627e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   414   200  8.526702e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(123611, 19)\n",
      "   mcsteps      1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  497.0  1053.0  957.0  110.0  31.0  0.0  138.0  0.0  0.0  28.0   \n",
      "1        0  497.0  1053.0  957.0  110.0  31.0  0.0  138.0  0.0  0.0  28.0   \n",
      "2        0  497.0  1053.0  957.0  110.0  31.0  0.0  138.0  0.0  0.0  28.0   \n",
      "3        0  497.0  1053.0  957.0  110.0  31.0  0.0  138.0  0.0  0.0  28.0   \n",
      "4        0  497.0  1053.0  957.0  110.0  31.0  0.0  138.0  0.0  0.0  28.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0    58   260  8.795903e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   127   278  8.526748e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   320    86  8.556866e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   426   147  8.526957e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   389    77  8.527442e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(174195, 19)\n",
      "   mcsteps      1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  998.0  1059.0  954.0  110.0  24.0  0.0  141.0  0.0  0.0  28.0   \n",
      "1        0  998.0  1059.0  954.0  110.0  24.0  0.0  141.0  0.0  0.0  28.0   \n",
      "2        0  998.0  1059.0  954.0  110.0  24.0  0.0  141.0  0.0  0.0  28.0   \n",
      "3        0  998.0  1059.0  954.0  110.0  24.0  0.0  141.0  0.0  0.0  28.0   \n",
      "4        0  998.0  1059.0  954.0  110.0  24.0  0.0  141.0  0.0  0.0  28.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0   419   318  8.526879e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   153   257  8.535946e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   202    53  8.527231e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   302    59  8.536351e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   121   130  8.528870e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(274522, 19)\n",
      "   mcsteps       1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  1988.0  1064.0  980.0  110.0  29.0  0.0  110.0  0.0  0.0  28.0   \n",
      "1        0  1988.0  1064.0  980.0  110.0  29.0  0.0  110.0  0.0  0.0  28.0   \n",
      "2        0  1988.0  1064.0  980.0  110.0  29.0  0.0  110.0  0.0  0.0  28.0   \n",
      "3        0  1988.0  1064.0  980.0  110.0  29.0  0.0  110.0  0.0  0.0  28.0   \n",
      "4        0  1988.0  1064.0  980.0  110.0  29.0  0.0  110.0  0.0  0.0  28.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0   262   196  9.054917e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1    92   109  8.679527e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   411   113  9.585515e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   413    95  8.532265e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   107   181  8.527046e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(371380, 19)\n",
      "   mcsteps       1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  2958.0  1065.0  984.0  109.0  30.0  0.0  108.0  0.0  0.0  29.0   \n",
      "1        0  2958.0  1065.0  984.0  109.0  30.0  0.0  108.0  0.0  0.0  29.0   \n",
      "2        0  2958.0  1065.0  984.0  109.0  30.0  0.0  108.0  0.0  0.0  29.0   \n",
      "3        0  2958.0  1065.0  984.0  109.0  30.0  0.0  108.0  0.0  0.0  29.0   \n",
      "4        0  2958.0  1065.0  984.0  109.0  30.0  0.0  108.0  0.0  0.0  29.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0   242   356  8.625129e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1    92   241  8.638730e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   228   230  8.541914e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3    89   420  8.535352e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   214   406  8.612076e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "(469718, 19)\n",
      "   mcsteps       1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  3929.0  1062.0  974.0  110.0  30.0  0.0  115.0  0.0  0.0  28.0   \n",
      "1        0  3929.0  1062.0  974.0  110.0  30.0  0.0  115.0  0.0  0.0  28.0   \n",
      "2        0  3929.0  1062.0  974.0  110.0  30.0  0.0  115.0  0.0  0.0  28.0   \n",
      "3        0  3929.0  1062.0  974.0  110.0  30.0  0.0  115.0  0.0  0.0  28.0   \n",
      "4        0  3929.0  1062.0  974.0  110.0  30.0  0.0  115.0  0.0  0.0  28.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0   180   177  8.555751e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   425   119  8.671062e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   300   170  8.722691e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   200   400  1.141548e-09  0.0  0.0   0.0  0.0  0.0  \n",
      "4   385   107  1.167906e-09  0.0  0.0   0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "for i in range(1, 8):\n",
    "    file_path = f'C:/Users/Ioannis/Documents/UvA thesis/UvA-thesis/data/merged_data/combined_data_batch_{i}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.drop(columns=['zCOM'], inplace=True)  # Drop the 'zCOM' column\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    data_frames.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    " class Model(tf.keras.Model):\n",
    "    def __init__(self, model_path, train_mode=True, input_dim=19, lstm_size=500, batch_size=4, e_learning_rate=1e-5):\n",
    "        super(Model, self).__init__()\n",
    "        self.model_path = model_path\n",
    "        self.train_mode = train_mode\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm_size = lstm_size\n",
    "        self.batch_size = batch_size\n",
    "        self.e_learning_rate = e_learning_rate\n",
    "\n",
    "        #define LSTM layer\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(units=self.lstm_size, return_sequences=True)\n",
    "\n",
    "        #define output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(units=2, activation=None)\n",
    "        # Define reshape layer\n",
    "        self.reshape_layer = tf.keras.layers.Reshape((500, 500))  # Reshape to match spatial dimensions\n",
    "\n",
    "        #define optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.e_learning_rate)\n",
    "\n",
    "        #define MSE as loss function\n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Reshape inputs to add sequence length dimension\n",
    "        inputs = tf.expand_dims(inputs, axis=1)\n",
    "        \n",
    "        # Input shape: (batch_size, sequence_length, input_dim)\n",
    "        x = self.lstm_layer(inputs)\n",
    "        # Output shape: (batch_size, sequence_length, lstm_size)\n",
    "        output = self.output_layer(x)\n",
    "        # Output shape: (batch_size, sequence_length, 2) - 2 for outputs\n",
    "        \n",
    "        # Reshape output to match spatial dimensions\n",
    "        output = self.reshape_layer(output)\n",
    "        return output\n",
    "\n",
    "    def train_step(self, xtrain, ytrain):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(xtrain, training=True)\n",
    "            loss = self.loss_fn(ytrain, y_pred)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    def train(self, train_set, valid_set, maxEpoch=10):\n",
    "        x_train, y_train = train_set\n",
    "        x_valid, y_valid = valid_set\n",
    "        \n",
    "        for epoch in range(maxEpoch):\n",
    "            train_loss = self.train_step(x_train, y_train)\n",
    "            valid_loss = self.loss_fn(y_valid, self(x_valid, training=False))\n",
    "            print(f\"Epoch {epoch + 1}, Train Loss: {train_loss}, Valid Loss: {valid_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df1 = data_frames[0]\n",
    "    \n",
    "    #convert the df to numpy array and cast the data to float\n",
    "    results = df1.to_numpy(dtype='float')\n",
    "\n",
    "    #define input indices and output indices\n",
    "    input_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "    output_indices = [11, 12] \n",
    "\n",
    "   # Split data into train and valid sets\n",
    "    train_size = int(len(results) * 0.9)\n",
    "    train_features = results[:train_size, input_indices]\n",
    "    train_targets = results[:train_size, output_indices]\n",
    "    valid_features = results[train_size:, input_indices]\n",
    "    valid_targets = results[train_size:, output_indices]\n",
    "\n",
    "    # Create train and valid sets with input features and targets\n",
    "    train_set = (train_features, train_targets)\n",
    "    valid_set = (valid_features, valid_targets)\n",
    "\n",
    "    #initialize and train the model\n",
    "    mymodel = Model(model_path=\"saved_model\")\n",
    "    mymodel.train(train_set, valid_set, maxEpoch=500)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 19, 32)            2295776   \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2320738 (8.85 MB)\n",
      "Trainable params: 2320738 (8.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_12/embedding_12/embedding_lookup' defined at (most recent call last):\n    File \"c:\\Program Files\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Program Files\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ioannis\\AppData\\Local\\Temp\\ipykernel_10588\\3608765077.py\", line 23, in <module>\n      history = model.fit(X_reshaped, Y, epochs=100, batch_size=32, validation_split=0.1, verbose=2)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_12/embedding_12/embedding_lookup'\nindices[0,0] = 800000 is not in [0, 71743)\n\t [[{{node sequential_12/embedding_12/embedding_lookup}}]] [Op:__inference_train_function_1369276]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Predict on the training data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_reshaped)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_12/embedding_12/embedding_lookup' defined at (most recent call last):\n    File \"c:\\Program Files\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Program Files\\Python38\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"c:\\Program Files\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ioannis\\AppData\\Local\\Temp\\ipykernel_10588\\3608765077.py\", line 23, in <module>\n      history = model.fit(X_reshaped, Y, epochs=100, batch_size=32, validation_split=0.1, verbose=2)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Ioannis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_12/embedding_12/embedding_lookup'\nindices[0,0] = 800000 is not in [0, 71743)\n\t [[{{node sequential_12/embedding_12/embedding_lookup}}]] [Op:__inference_train_function_1369276]"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 19)\n",
    "output_shape = 2\n",
    "embedding_size = 32 \n",
    "#num_unique_locations = 250000 #as 500x500 spatial data\n",
    "num_unique_locations = len(set(df1.iloc[:, 11].unique()) | set(df1.iloc[:, 12].unique()))\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_unique_locations, output_dim=embedding_size, input_length=input_shape[1]),\n",
    "    #Flatten(), \n",
    "    LSTM(units=64, return_sequences=False),\n",
    "    Dense(units=output_shape)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "X = df1.iloc[:, :19]\n",
    "Y = df1.iloc[:, 11:13]\n",
    "\n",
    "X_reshaped = X.values  # Remove the extra dimension\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_reshaped, Y, epochs=100, batch_size=32, validation_split=0.1, verbose=2)\n",
    "\n",
    "# Predict on the training data\n",
    "y_pred = model.predict(X_reshaped)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rounded = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of input features (X):\n",
      "   mcsteps     1       2      3      4     5    6      7    8    9    10  \\\n",
      "0        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "1        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "2        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "3        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "4        0  10.0  1072.0  972.0  109.0  25.0  0.0  121.0  0.0  0.0  29.0   \n",
      "\n",
      "   xCOM  yCOM           il8  il1  il6  il10  tnf  tgf  \n",
      "0    84   376  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "1   432   181  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "2   409   105  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "3   247   394  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "4   132   141  8.526701e-10  0.0  0.0   0.0  0.0  0.0  \n",
      "\n",
      "Sample of scaled target variables (Y):\n",
      "   xCOM  yCOM\n",
      "0    84   376\n",
      "1   432   181\n",
      "2   409   105\n",
      "3   247   394\n",
      "4   132   141\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of input features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nSample of scaled target variables (Y):\")\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
